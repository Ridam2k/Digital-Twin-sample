{
  "doc_title": "Work Experience: Computer Vision Research and ML",
  "source_url": "",
  "personality_ns": "technical",
  "content_type": "work_experience",
  "body": "In my journey through the realms of computer vision (CV) and machine learning (ML), I have engaged in a variety of research projects that have significantly honed my technical skills and deepened my understanding of the research-to-implementation gap. My work has primarily revolved around academic projects, personal initiatives, and roles such as a research assistant, where I focused on both foundational theories and practical applications.\n\n### Research Context and Specific Projects\n\nOne of my notable projects was implementing **semantic segmentation using PSPNet**. This involved leveraging the Pyramid Scene Parsing Network (PSPNet) architecture to achieve pixel-wise classification of images. I undertook the entire process from initial dataset handling, where I utilized common datasets like Cityscapes, to training pipelines that encompassed extensive hyperparameter tuning. I employed **PyTorch** for model implementation, which allowed me to leverage its dynamic computational graph for easier debugging and experimentation. \n\nIn parallel, I explored **diffusion models (DDPM)** and **conditional generation** techniques. My work with diffusion models involved understanding their latent space and the iterative denoising process that enables high-quality image generation. I implemented a DDPM framework where I experimented with various noise schedules and denoising networks, analyzing how these choices impacted the quality of generated samples.\n\n### Multimodal Projects\n\nBeyond traditional CV tasks, I ventured into **multimodal projects** like speech emotion recognition and fake news detection. In the speech emotion recognition project, I integrated audio signals with text data to classify emotions using a combination of CNNs and LSTMs. The fake news detection project involved training models on multimodal datasets (text and images) to identify misinformation. Here, I leveraged **TensorFlow** to build and experiment with various architectures, focusing on feature extraction from both modalities.\n\n### My Role and Technical Skills Developed\n\nIn these projects, I assumed a hands-on role that encompassed:\n- **Implementation**: Writing the code for model architectures and training routines.\n- **Experimentation**: Conducting experiments to test various hypotheses about model architectures and training methodologies. \n- **Evaluation**: Developing evaluation metrics such as Intersection over Union (IoU) for segmentation tasks and accuracy/F1 scores for classification tasks in multimodal projects.\n- **Paper Reading and Reproduction**: Engaging with current literature to replicate and extend findings from key papers, which deepened my understanding of theoretical underpinnings.\n\nThrough these experiences, I developed proficiency in dataset handling, building efficient training pipelines, and conducting hyperparameter tuning\u2014skills crucial for optimizing model performance.\n\n### Evaluation Approaches\n\nA significant aspect of my experience involved rigorous evaluation approaches. For the semantic segmentation tasks, I utilized **IoU** and pixel accuracy as primary metrics to assess model performance. In the context of the DDPM, I conducted **ablation studies** to dissect the impact of different components on the overall model performance, shedding light on which elements were most crucial for generating high-quality outputs.\n\n### Lessons Learned\n\nOne of the most profound insights from my work has been understanding the **research-to-implementation gap**. While theoretical frameworks and models can demonstrate excellent performance in controlled settings, translating these theories into practical applications often requires addressing real-world complexities, such as data variability and computational constraints. This realization has instilled in me a mindset focused on **iterative refinement and empirical validation**, emphasizing the need for continuous evaluation and adaptation of models in deployment scenarios.\n\n### Shaping My Understanding of ML Systems\n\nUltimately, this body of work has shaped my understanding of ML systems by emphasizing the importance of **system correctness** and **measurable improvement**. I have learned that successful ML implementations are not merely about achieving high accuracy on benchmark datasets but also about ensuring robustness, explainability, and ethical considerations in deployment. This holistic view has guided my approach to ML systems, reinforcing my commitment to building solutions that are not only technically rigorous but also socially responsible. \n\nIn summary, my research and project work in computer vision and machine learning has"
}