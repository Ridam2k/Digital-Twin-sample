{
  "doc_title": "Agent Reliability: Retries vs Guardrails",
  "source_url": "",
  "personality_ns": "technical",
  "content_type": "design_decision",
  "body": "In my experience working on LLM agent orchestration, I have encountered various reliability challenges that stem from the nature of language models. Particularly, agents can hallucinate tool calls, generate malformed inputs, or even enter infinite loops. Addressing these issues requires a nuanced architectural approach that incorporates strategies for both retries and guardrails.\n\n### The Reliability Problem\n\nThe reliability problem is multifaceted:\n- **Hallucinated Tool Calls:** Agents may produce calls to tools that do not exist or are not defined in the current context, leading to failures in execution.\n- **Malformed Inputs:** Inputs generated by the LLM can sometimes violate expected formats or constraints, resulting in errors during processing.\n- **Infinite Loops:** In some cases, agents can become trapped in cycles of execution, repeatedly generating similar outputs without progressing.\n\n### Strategies for Reliability\n\nTo tackle these challenges, I employ two primary strategies: **retries** and **guardrails**.\n\n1. **Retries:**\n   - This approach involves regenerating responses when an initial attempt fails, allowing the LLM another chance to produce a suitable output.\n   - I typically use retries in scenarios where:\n     - **Transient Errors:** These are temporary failures in the system, such as network issues, where a second attempt might succeed.\n     - **Ambiguous but Recoverable Failures:** If the LLM generates an output that is close to being correct but not quite there, I trust it to self-correct upon retrying.\n     - **Trust in Self-Correction:** When I have sufficient confidence in the LLM's ability to refine its output through iterations, retries can help achieve the desired outcome.\n\n2. **Guardrails:**\n   - Guardrails act as a validation layer, ensuring that tool calls and inputs are checked before execution. This can prevent many potential issues from arising in the first place.\n   - I prefer using guardrails in:\n     - **Safety-Critical Operations:** Any action that could significantly impact user safety or system integrity demands stringent validation.\n     - **Structured Output Requirements:** When the output must conform to strict formats, guardrails can ensure compliance.\n     - **Deterministic Validation:** In cases where the validation criteria are well-defined and can be programmatically enforced, guardrails can effectively mitigate risks.\n\n### Hybrid Approach\n\nIn my architectural design, I often combine both strategies:\n- **Guardrails for Validation:** I implement guardrails to filter out invalid tool calls or malformed inputs before they are executed. This initial layer of protection is crucial.\n- **Retries for Recovery:** If a valid call fails unexpectedly, I utilize retries to allow the agent to recover gracefully without escalating into failure states.\n\n### Concrete Example\n\nIn a recent project involving LLM agent orchestration for a customer support system, I implemented a hybrid approach. The system was tasked with fetching information from various APIs based on user queries. \n\n- **Guardrails:** Before executing any API calls, the system validated inputs against predefined schemas, ensuring that the calls were well-formed and aligned with the expected API specifications.\n- **Retries:** During high-traffic periods, certain API calls would occasionally fail due to rate limiting. In these instances, the agent was programmed to retry the call a limited number of times before giving up.\n\n### Tradeoffs\n\nWhile both strategies enhance reliability, they come with tradeoffs:\n- **Retries** can introduce additional latency and costs due to repeated processing. Each retry requires resources and time, which can impact overall system performance.\n- **Guardrails** necessitate upfront engineering efforts to define validation criteria and implement them, which can delay initial deployment.\n\n### Lessons Learned\n\nThrough my work, I have discerned several key lessons:\n- **Failure Modes:** Retries effectively handle transient errors and some ambiguous failures but can lead to increased latency if overused. Guardrails excel at preventing systemic issues but require comprehensive design upfront.\n- **When to Give Up vs. Keep Retrying:** It is crucial to define thresholds for retries based on specific use cases."
}